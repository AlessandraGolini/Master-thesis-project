### First attempt to analyze and plot the data of JRC: Maximum Daily Global Open Ocean Water Level from LISCOAST

## Import modules and preparation
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import glob
import os
import netCDF4
from netCDF4 import Dataset
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import plotly.express as px
from scipy.interpolate import griddata

## Import data
# Import data from working directory
file_paths = sorted(glob.glob(r"C:/Users/aless/Desktop/dati_tesi/globalDailyMaxWaterLevel/VER2024-05-03/*.nc"))

# Checking for the presence and validity of files in the working directory
valid_files = []
invalid_files = []

for filepath in file_paths:
    if os.path.isfile(filepath) and filepath.endswith(".nc"):
        try:
            ds = Dataset(filepath)
            ds.close()
            valid_files.append(filepath)
        except:
            invalid_files.append(filepath)
    else:
        invalid_files.append(filepath)
print(f"✅ Valid NetCDF files: {len(valid_files)}")
print(f"❌ Unreadable NetCDF files: {len(invalid_files)}")

# Examples of invalid or unreadable files
if invalid_files:
    print("Examples of invalid or unreadable files:")
    for f in invalid_files[:5]:
        print(" -", f)

# Information about the files
data_list = []
ds = Dataset(file_paths[0])
print(f"Information about the files:")
print(ds)

# Represented variables
print(f"Variables represented in the files:")
print(ds.variables.keys())

# Focus on the water level variable 
var = ds.variables['waterLevelreanalysis'][:]  
print(f"Water Level variable size: {var.shape}")

ds.close()

# Trying to understand the data
ds = xr.open_dataset(file_paths[0])
print(ds)
print(ds.coords)  # coordinates
print(ds.dims)    # dimensions

# unit measure of water level
ds['waterLevelreanalysis'].attrs

# Verify coordinates
longs = ds_concat.longitudeSAT.values
print("Longitudine SAT - range:", longs.min(), "→", longs.max())
print("Total number of pointsSAT:", len(longs))
print("Unique longitudes:", np.unique(np.round(longs, 3)))
print("Latitue SAT - range:", lats.min(), "→", lats.max())
print("Total number of pointsSAT:", len(lats))
print("Unique latitudes:", np.unique(np.round(lats, 3)))


## Keta Basin, Ghana
# Search for files including points in the longitude range [-3°, +3°], that is the Keta Basin, Ghana
target_files = []

for f in file_paths:
    with xr.open_dataset(f) as ds:
        lons = ds["longitudeSAT"].values
        if ((lons >= -3) & (lons <= 4)).any():
            target_files.append(f)

print(f"Found {len(target_files)} files containing Keta Basin longitudes")            

# Open and concatenate datasets
def load_and_filter(file):
    ds = xr.open_dataset(file)
    mask_lon = (ds.longitudeSAT >= -3) & (ds.longitudeSAT <= 4)
    mask_lat = (ds.latitudeSAT >= 0) & (ds.latitudeSAT <= 7)
    mask = mask_lon & mask_lat
    ds = ds.sel(pointsSAT=mask)
    return ds

# Apply filtering and merge
filtered_keta = [load_and_filter(f) for f in target_files]

# Align datasets explicitly before concatenating (force same structure)
#keta_ds = xr.align(*filtered_keta, join="override")
filtered_keta = [ds for ds in filtered_keta if ds.dims["pointsSAT"] > 0]
keta_ds = xr.concat(filtered_keta, dim="pointsSAT")

print("Longitude range:", float(keta_ds.longitudeSAT.min()), "to", float(keta_ds.longitudeSAT.max()))
print("Latitude range:", float(keta_ds.latitudeSAT.min()), "to", float(keta_ds.latitudeSAT.max()))

